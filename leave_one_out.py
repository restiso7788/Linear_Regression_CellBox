# -*- coding: utf-8 -*-
"""Leave_one_out.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PXU2UaBnJav5Mce-IJ7ci-HYlPFU7GpX
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import statistics

df = pd.read_csv('/content/expert.csv')

# leave_one drug out

clf = LinearRegression()
def logistic_regression(response,train,test,tags,temp_data):
    new_df = pd.DataFrame()
    for i in range(response.shape[1]-12):
        y = response.iloc[:,i]
        train_y = y[y.index.isin(tags)]
        test_y = y[~y.index.isin(tags)]   
        clf.fit(train, train_y)      
        clf_y = clf.predict(test)
        new_reponse = test_y.name
        new_df[new_reponse] = clf_y
    return new_df
results_dict = {}
for i in range(-12,0):
    col = df.columns[i]
    
    train = df[df[col] == 0]
    train_tag = train.index
    
    X = df.iloc[:,-12:]
    train_x = X[X.index.isin(train_tag)]
    test_x = X[~X.index.isin(train_tag)]
    
    temp_data = df[~df.index.isin(train_tag)].iloc[:,:87].reset_index(drop = True)
    
    my_result = logistic_regression(df, train_x, test_x, train_tag, temp_data)
    my_result_x = temp_data
    x_all = my_result_x.values.flatten()
    my_result_y = my_result
    y_all = my_result_y.values.flatten()
    r = np.corrcoef(x_all, y_all)[0][1]
    
    results_dict[col] = r
    
print(results_dict)

values = results_dict.values()
statistics.mean(values)